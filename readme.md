#### 文本情感分析经典算法

- 情感字典算法：

  - 字典中有情感词，包括积极消极程度等词语；输入新的句子后，将句子进行分词等处理，然后通过字典查阅最终得出结论，分别为0，1，-1，即中性、积极、消极；
  - 参考  [hellonlp/sentiment_analysis_dict: sentiment analysis、情感分析、文本分类、基于字典、python、classification (github.com)](https://github.com/hellonlp/sentiment_analysis_dict)
  - 代码对应 ./dict ，可以使用 python  predict.py 的方式运行，会给出一个两分类（消极积极）的数据集的预测acc；

- 机器学习算法

  - 主要是机器学习的分类算法，使用 朴素贝叶斯，LinearSVM，KNN，以及随机森林

  - 处理步骤为：

    - 数据预处理：进行分词（jieba库）、消除标点符号、消除停用词等
    - 划分数据集：将数据集按照8：2的比例划分为训练集和测试集；
    - 特征提取：将分词后结果转化为TFIDF，然后进行训练；
    - 模型训练：使用sklearn库中的 上述四种机器学习算法，完成模型训练；
    - 模型验证：使用测试集进行性能测试
    - 后续（可能是明天）改进：使用交叉验证方法测试准确性；使用网格搜索的方法确定模型超参数；

  - 数据集：weibo_4_moods数据集

  - 代码介绍及使用：

    - segment.py：无参数，直接 python segment.py 运行，输入为原始文件（csv），输出为预处理完成后的文件（pre.csv）；

    - train.py：无参数，直接 python train.py 运行，输入为预处理后的数据，会打印出训练后的评价指标，分别为正确率，准确率，召回率以及 F1_score ；同时，会将训练好的模型参数保存进 saved_model 文件夹中，以供后续使用；

      其中，每个模型的准确率结果写在对应的注释中了，可以不用跑了，因为随机森林的复杂度比较高；

      还有如果想要看每个模型的参数，sklearn有对应的函数，搜一下就行。

    - test.py：无参数，直接 python test.py运行，文件中 text 为测试句子，通过载入训练好的模型的方式，打印出预测结果。

  - 文件中，有分别对应1，2，3；1是weibo_4_moods的数据集，2是weibo_2_moods数据集（10000条记录，数据比例1比1）；3也是2moods，但是是做过停用词处理的，尽管效果并不好  o.O

- nlpcc：

  ​		是在找数据集的时候找的一个数据集，这是一个nlp比赛提供的数据集，详细可以查一下，因为前两个数据集肉眼可见的奇怪，所以想找一个比较权威的数据集。要是明天不懒的话再处理一下数据，试试这几种方法在那个上面的效果。

- 现在我要取Timi了，你们加油